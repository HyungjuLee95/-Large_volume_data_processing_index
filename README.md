# -Large_volume_data_processing_index
대용량데이터 처리의 꽃, INDEX를 알아보고, 성능 비교를 해보자

## 생각
![image](https://github.com/HyungjuLee95/-Large_volume_data_processing_index/assets/111270174/e29f7b24-b50c-46fa-ae04-0e413025d437)

CPU가 데이터를 가져오거나 저장하기 위해서는 I/O(입출력) 버스를 통하게 되며, 아래 장치들로 데이터를 보내게된다.<br>
여기서 저장하기 위한 용도로 메모리와 디스크를 사용한다. 생각을 해본다면 결국에는 데이터는 디스크에 저장이 되어야한다.<br>
<strong>디스크는 메모리에 비해 속도가 느리기 때문에, 결국! 데이터베이스 성능의 핵심은 디스크 I/O를 최소화 하는 것이다.</strong><br>

### 어떻게?
메모리에 올라온 데이터로 최대한 요청을 처리하는 것 => 메모리 캐시 히트율을 높이는 것<br>
읽기 쓰기 중, 쓰기도 메모리에 먼저 쓰는 방법 -> 전원이 꺼져 메모리에 저장한 데이터가 유실된다면? 이것을 고려하여 WAL(Write Ahead Log)를 사용.<br>

![image](https://github.com/HyungjuLee95/-Large_volume_data_processing_index/assets/111270174/effadfd0-59cc-41e8-bb46-babed49c9899)<br>
랜덤I/O 정말 무작위로 데이터를 가져오는 것.<br>
순차 I/O 연속된 블락의 데이터를 읽어오는 것.<br>

대부분의 트랜잭션은 무작위하게 Write가 발생한다.<br>
예를 들어 A테이블의 10번 ID를 업데이트를 하거나, 100 번 ID를 가진 걸 업데이트를 할 수 있는데, 이를 보면 대부분 무작위하게 Write할 수 있음.<br>
앞에서 언급한 wal은 하나의 파일에 끝부분부터 순차적으로 write만 쌓아두는 것.<br><br>

즉, 이렇게 하게된다면 랜던 I/O보다는 순자 I/O가 진행이 된다.<br><br>

그래서! 데이터베이스는 업데이트는 디스크에 가서 저장하는 것은 비효율적이기 때문에 메모리에 쌓아두고 한번에 넣으면 되잖아! 라는 생각을 할 수 있다.<br>
그럼 전원이 꺼지게된다면? 데이터가 유실이 된다면 파일에 순차적으로 쌓아두었던 로그를 순차적으로 실행시키면 다시 복구할 수 있다.<br><br>

### Index?
-> 정렬된 자료 구조, 이를 통해 탐색 볌위를 최소<br>
아래 테이를 봐보자<br>
![image](https://github.com/HyungjuLee95/Large_volume_data_processing_index/assets/111270174/e46faae0-a410-47d0-8009-3047d0462991)<br>

앞 번호는 pk라고 생각할 수 있고, 만약 여기서 나이가 가장 낮은 데이터를 찾고싶다고하자.<br>
칼럼을 순서대로 돌면서 아마 나이들을 확인하고 어딘가에 저장할 것이다.<br>
여기서 나이를 index로 설정을 한다면, 아래처럼 인덱스별로 정렬이 되어있으면, 첫번째 데이터를 찾고 해당 인덱스를 찾아간다.<br>
![image](https://github.com/HyungjuLee95/Large_volume_data_processing_index/assets/111270174/ceb06db6-f4a5-4f54-83db-9b99afaa9e4e)<br><br>

주의할 것은! 인덱스도 테이블이다!<br>
실제로 데이터 베이스는 쿼리가 들어오면 index를 한번 확인하고, index를 조회한 후, 원본 데이터를 찾아가게된다.<br>
<strong>즉, 인덱스의 핵심은 정렬을 통해 탐색(검색) 범위를 최소화하는 것.</strong><br><br>

### 그렇다면 검색이 빠른 자료 구조는 무엇이 있을까?<br>
Hash Map, List, Binary Search Tree<br>
#### 하나씩 확인해보자
1. HashMap<br>
> a) 단건 검색 속도O(1) -> key와 value가 있기에 충돌이 있음을 감안하더라도 상수시간 안에 가능하다<br>
> b) 범위 탐색은 O(N) -> 예를 들어서 key가 나이로 되어있다면, HashMap은 전체를 다 보아야할 것이다.<br>
> c) 전방 일치 탐색 불가 -> 예를 들어서 'like 'AB%' 라고 쿼리가 나갔을 때, Hash Map은 하나하나 key를 다 꺼내서 확인을 해보아야한다.<br><br>
2. List<br>
> a)정렬되지 않은 리스트의 탐색은 O(N)<br>
> b) 정렬된 리스트의 탐색은 O(logN)<br>
> c) 정렬되지 않은 리스트의 정렬 시간 복잡도 O(N) ~ )(N*logN)<br>
> d) 삽입/ 삭제 비용이 매우 높음 -> 왜? 중간 것을 삭제한다면 앞이든 뒤든 다 꺼낸다음 삭제하고 다시 넣어야하기 때문이다.<br><br>
3. Binary Search Tree<br>
> a) 트리 높이에 따라 시간 복잡도가 결정됨 -> Binary Search을 이용한다는 기준 하에 트리 높이에 따라서 결덩이 된다.<br>
> b) 트리 높이를 최소화하는 것이 중요<br>
> c) 한쪽으로 노드가 치우치지 않도록 균형을 잡아주는 트리 사용 -> Red Black Tress, B+Tree<br>
> -> 대부분 B+Tree를 사용함<br><br>
4.B+Tree<br>
> a) 삽입 / 삭제시 항상 균형을 이룸<br>
> b) 하나의 노드가 여러 개의 자식 노드를 가질 수 있음<br>
> c) 리프노드에만 데이터 존재<br>
> ->연속적인 데이터 접근시 유리<br>(b Tree와의 차이는 각 node가 데이터가 된다. 다만 B+Tree는 리프 노드에만 데이터가 존재하고, 위에 노드들은 데이터를 찾아가기 위한 Key가 된다. 그래서 연속적인 데이터를 접근할 때 리프 노드만 흝으면 된다. )<br>
> ※Pk를 가지고 있는 B+tree를 생각해 보았을 때, 데이터를 삭제하거나 삽입할 때, B+Tree의 모습이 바뀌는데, 이러한 것은 데이터에서도 동일하게 일어난다. 그 말은 즉슨, 조회의 속도는 높일 수 있으나, 쓰기나 갱신의 성능을 낮출 수 있으므로 벨런스를 잡는 것이 중요하다. 



